{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML21-HW05-Translation(Seq2Seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Reference:\n",
    "\n",
    "- main\n",
    "    - https://zhuanlan.zhihu.com/p/106902569\n",
    "    - https://zhuanlan.zhihu.com/p/347061440\n",
    "    - https://colab.research.google.com/github/ga642381/ML2021-Spring/blob/main/HW05/HW05.ipynb\n",
    "    - https://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
    "    \n",
    "- utils\n",
    "    - https://docs.python.org/3/howto/logging.html#logging-basic-tutorial\n",
    "\n",
    "Architecture:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data\n",
    "\n",
    "The data has already been downloaded to local. Check original code from TA's for download information.\n",
    "\n",
    "- Extract the .tgz files `./data/ted2020.tgz` to `./data/raw/`.\n",
    "\n",
    "- Clean raw data and save the result to `./data/clean/`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip `.tgz` File\n",
    "\n",
    "(These code blocks credit to `shopping le macaca`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "src_path = './data/ted2020.tgz'\n",
    "unzip_dir = './data/raw'\n",
    "Path(unzip_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with tarfile.open(src_path) as tf:\n",
    "    tf.extractall(unzip_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some data\n",
    "with open(unzip_dir + '/raw.en') as en_file:\n",
    "    en_data = en_file.read().splitlines()\n",
    "with open(unzip_dir + '/raw.zh') as zh_file:\n",
    "    zh_data = zh_file.read().splitlines()\n",
    "for i in range(5):\n",
    "    print(en_data[i])\n",
    "    print(zh_data[i])\n",
    "with open(unzip_dir + '/raw.en') as en_r:\n",
    "    endata = en_r.readline()\n",
    "    print(endata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "- clean data\n",
    "- save data to `.json` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class DataPreprocessor:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - en_filepath (:obj:`str`) :\n",
    "        filepath of raw en-corpus\n",
    "    - zh_filepath (:obj:`str`) :\n",
    "        filepath of raw zh-corpus\n",
    "    - is_test (:obj:`bool` | False) :\n",
    "        whether the input files are for testing\n",
    "    - ratio (:obj:`int` | 9) :\n",
    "        threshold ratio between senctence lengths of en and zh\n",
    "    - max_len (:obj:`int` | 1000) :\n",
    "        maximum length of each sentence\n",
    "    - min_len (:obj:`int` | 1) :\n",
    "        minimum length of each sentence\n",
    "\n",
    "    function call:\n",
    "    - cleans en- and zh-corpus\n",
    "    - return tuple of lists (en-corpus, zh-corpus)\n",
    "    \"\"\"\n",
    "    def __call__(self, en_filepath : str, zh_filepath : str, is_test=False, ratio=9, max_len=400, min_len=1):\n",
    "        en_path = Path(en_filepath)\n",
    "        zh_path = Path(zh_filepath)     \n",
    "        en_clean_corpus = []\n",
    "        zh_clean_corpus = []\n",
    "        # start clean\n",
    "        if is_test:\n",
    "            with en_path.open(mode='r') as r:\n",
    "                for s in r:\n",
    "                    s = s.strip()\n",
    "                    s = self.__clean_string__(s, 'en')\n",
    "                    en_clean_corpus.append(s)\n",
    "        else:\n",
    "            with en_path.open(mode='r') as ren:\n",
    "                with zh_path.open(mode='r') as rzh:\n",
    "                    for s_en in ren:\n",
    "                        s_en = s_en.strip()\n",
    "                        s_zh = rzh.readline().strip()\n",
    "                        s_en = self.__clean_string__(s_en, 'en')\n",
    "                        s_zh = self.__clean_string__(s_zh, 'zh')\n",
    "                        if self.__drop__(\n",
    "                            self.__get_strlen__(s_en, 'en'),\n",
    "                            self.__get_strlen__(s_zh, 'zh'),\n",
    "                            min_len, max_len, ratio):\n",
    "                            continue\n",
    "                        en_clean_corpus.append(s_en)\n",
    "                        zh_clean_corpus.append(s_zh)\n",
    "        return en_clean_corpus, zh_clean_corpus\n",
    "    \n",
    "    def __drop__(self, en_len, zh_len, min_len, max_len, ratio):\n",
    "        \"\"\"check whether the input strings pass the given thresholds\"\"\"\n",
    "        if en_len < min_len or zh_len < min_len:\n",
    "            return True\n",
    "        if en_len > max_len or zh_len > max_len:\n",
    "            return True\n",
    "        if en_len/zh_len > ratio or zh_len/en_len > ratio:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def __f2h__(self, fstr : str):\n",
    "        \"\"\"convert full-width string to half-width string\"\"\"\n",
    "        # reference: https://www.cnblogs.com/kaituorensheng/p/3554571.html\n",
    "        # half-width string splitter\n",
    "        hss = []\n",
    "        for s in fstr:\n",
    "            num = ord(s)\n",
    "            if num == 12288:\n",
    "                num = 32\n",
    "            elif 65281 <= num <= 65374:\n",
    "                num -= 65248\n",
    "            hss.append(chr(num))\n",
    "        return ''.join(hss)\n",
    "    \n",
    "    def __get_strlen__(self, s : str, lang : str):\n",
    "        if lang == \"zh\":\n",
    "            return len(s)\n",
    "        return len(s.split())\n",
    "        \n",
    "    def __clean_string__(self, s : str, lang : str):\n",
    "        if lang == 'en':\n",
    "            s = re.sub(r\"\\([^()]*\\)\", \"\", s) # remove ([text])\n",
    "            s = s.replace('-', '') # remove '-'\n",
    "            # Each word in en-string is separated by space, and in order\n",
    "            #   to keep punctuation for training, we also add space between\n",
    "            #   word and punctuation.\n",
    "            # For example,\n",
    "            #   \"hello, this is an example!\" becomes\n",
    "            #   \"hello ,  this is an example ! \"\n",
    "            s = re.sub('([.,;:!?()\\\"])', r\" \\1 \", s)\n",
    "            # Continue the above example, the result becomes\n",
    "            #   \"hello , this is an example !\"\n",
    "            s = ' '.join(s.strip().split())\n",
    "        elif lang == 'zh':\n",
    "            s = self.__f2h__(s)\n",
    "            s = re.sub(r\"\\([^()]*\\)\", \"\", s)\n",
    "            s = s.replace(' ', '')\n",
    "            s = s.replace('-', '')\n",
    "            s = s.replace('“', '\"')\n",
    "            s = s.replace('”', '\"')\n",
    "            s = s.replace('_', '')\n",
    "            # For zh-string, each character is a word, and hence either we\n",
    "            #   add space between each of the word and punctuation like\n",
    "            #   we deal with en-string( which will cause a lot of memory waste)\n",
    "            #   or we deal the zh-string compactly( no sapce between word and punctuation).\n",
    "            # We choose the second solution, and the example would be\n",
    "            #   \"你好,這是一個例子!\"\n",
    "            #s = re.sub('([。,;:!?()\\\"~「」])', r' \\1 ', s)\n",
    "            s = s.strip()\n",
    "        return s\n",
    "    \n",
    "def save_data(save_dir, en_corpus, zh_corpus):\n",
    "    odir = Path(save_dir)\n",
    "    odir.mkdir(parents=True, exist_ok=True)\n",
    "    with open(odir / \"clean.en\", 'w') as ofile:\n",
    "        for s in en_corpus:\n",
    "            print(s, file=ofile)\n",
    "    with open(odir / \"clean.zh\", 'w') as ofile:\n",
    "        for s in zh_corpus:\n",
    "            print(s, file=ofile)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you so much , Chris .\n",
      "非常謝謝你,克里斯。能有這個機會第二度踏上這個演講台\n",
      "And it's truly a great honor to have the opportunity to come to this stage twice ; I'm extremely grateful .\n",
      "真是一大榮幸。我非常感激。\n",
      "I have been blown away by this conference , and I want to thank all of you for the many nice comments about what I had to say the other night .\n",
      "這個研討會給我留下了極為深刻的印象,我想感謝大家對我之前演講的好評。\n",
      "And I say that sincerely , partly because I need that .\n",
      "我是由衷的想這麼說,有部份原因是因為——我真的有需要!\n",
      "Put yourselves in my position .\n",
      "請你們設身處地為我想一想!\n",
      "en sentences : 393992\n",
      "zh sentences : 393992\n",
      "Thank you so much , Chris .\n",
      "非常謝謝你,克里斯。能有這個機會第二度踏上這個演講台\n",
      "And it's truly a great honor to have the opportunity to come to this stage twice ; I'm extremely grateful .\n",
      "真是一大榮幸。我非常感激。\n",
      "I have been blown away by this conference , and I want to thank all of you for the many nice comments about what I had to say the other night .\n",
      "這個研討會給我留下了極為深刻的印象,我想感謝大家對我之前演講的好評。\n",
      "And I say that sincerely , partly because I need that .\n",
      "我是由衷的想這麼說,有部份原因是因為——我真的有需要!\n",
      "Put yourselves in my position .\n",
      "請你們設身處地為我想一想!\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "dp = DataPreprocessor()\n",
    "en_corpus, zh_corpus = dp(\"./data/raw/raw.en\", \"./data/raw/raw.zh\")\n",
    "for i in range(5):\n",
    "    print(en_corpus[i])\n",
    "    print(zh_corpus[i])\n",
    "\n",
    "# save file to json\n",
    "save_data(\"./data/clean\", en_corpus, zh_corpus)\n",
    "# load data for checking\n",
    "clean_en = []\n",
    "clean_zh = []\n",
    "with open(\"./data/clean/clean.en\", 'r') as ifile:\n",
    "    clean_en = ifile.readlines()\n",
    "with open(\"./data/clean/clean.zh\", 'r') as ifile:\n",
    "    clean_zh = ifile.readlines()\n",
    "print(f\"en sentences : {len(clean_en)}\")\n",
    "print(f\"zh sentences : {len(clean_zh)}\")\n",
    "for i in range(5):\n",
    "    print(clean_en[i].strip())\n",
    "    print(clean_zh[i].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token (sentencepiece)\n",
    "\n",
    "- Train tokenizers and save models under `./token/tokenizer/`.\n",
    "\n",
    "- Tokenize data from\n",
    "\n",
    "  - `./data/clean/clean.en`\n",
    "\n",
    "  - `./data/clean/clean.zh`\n",
    "  \n",
    "  to `./token/data/train_token.json`.\n",
    "\n",
    "  In order to speed up training process, we save tokenized data in this block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max tokens length 464\n",
      "['▁hello', '▁world', '▁,', '▁this', '▁is', '▁for', '▁test', '▁.']\n",
      "[5824, 277, 10, 74, 64, 85, 1145, 14]\n",
      "['▁', '椰', '奶', '不是', '產', '自', '椰', '羊', '所以', '請', '不要', '騷', '擾', '椰', '羊', '!']\n",
      "[2044, 4825, 3531, 28, 2280, 2108, 4825, 3594, 15, 2578, 465, 4097, 3356, 4825, 3594, 2413]\n",
      "椰奶不是產自椰羊所以請不要騷擾椰羊!\n",
      "tokens length : 464\n",
      "thank you so much , chris .\n",
      "非常謝謝你,克里斯。能有這個機會第二度踏上這個演講台\n",
      "and it's truly a great honor to have the opportunity to come to this stage twice ; i'm extremely grateful .\n",
      "真是一大榮幸。我非常感激。\n",
      "i have been blown away by this conference , and i want to thank all of you for the many nice comments about what i had to say the other night .\n",
      "這個研討會給我留下了極為深刻的印象,我想感謝大家對我之前演講的好評。\n",
      "and i say that sincerely , partly because i need that .\n",
      "我是由衷的想這麼說,有部份原因是因為——我真的有需要!\n",
      "put yourselves in my position .\n",
      "請你們設身處地為我想一想!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sentencepiece as spm\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"datapath_config\" : {\n",
    "        \"clean\" : [\"./data/clean/clean.en\", \"./data/clean/clean.zh\"],\n",
    "    },\n",
    "    \"spm_config\" : {\n",
    "        \"vocab_size\" : 8000,\n",
    "        \"dir\" : \"./token\",\n",
    "        \"model_type\" : \"bpe\",\n",
    "        \"nm_rule\" : \"nmt_nfkc_cf\",\n",
    "        \"character_coverage\" : 1,\n",
    "        \"input_sentence_size\" : 1e6,\n",
    "        \"shuffle_input_sentence\" : True,\n",
    "        \"pad_id\" : 0,\n",
    "        \"unk_id\" : 1,\n",
    "        \"bos_id\" : 2,\n",
    "        \"eos_id\" : 3,\n",
    "    },\n",
    "}\n",
    "\n",
    "class SpmTokenHandler:\n",
    "    def __init__(self, spm_config, datapath_config):\n",
    "        self.spm_config = spm_config\n",
    "        self.datapath = datapath_config['clean']\n",
    "        # make directory for models\n",
    "        model_dir = Path(spm_config['dir']) / \"tokenizer\"\n",
    "        model_dir.mkdir(parents=True, exist_ok=True)\n",
    "        # get spm model prefix\n",
    "        self.en_model_prefix = model_dir / f\"spm{spm_config['vocab_size']}en\"\n",
    "        self.zh_model_prefix = model_dir / f\"spm{spm_config['vocab_size']}zh\"\n",
    "    \n",
    "    def __get_model_path__(self):\n",
    "        \"\"\"get spm model path\"\"\"\n",
    "        return Path(f\"{self.en_model_prefix}.model\"), Path(f\"{self.zh_model_prefix}.model\")\n",
    "    \n",
    "    def __check_spm_model__(self):\n",
    "        \"\"\"check whether spm-models exist, if not, create them\"\"\"\n",
    "        en_model_path, zh_model_path = self.__get_model_path__()\n",
    "        if not en_model_path.exists():\n",
    "            self.__train_tokenizer__(filepath=self.datapath[0], model_prefix=self.en_model_prefix, **self.spm_config)\n",
    "        if not zh_model_path.exists():\n",
    "            self.__train_tokenizer__(filepath=self.datapath[1], model_prefix=self.zh_model_prefix, **self.spm_config)\n",
    "\n",
    "    def __train_tokenizer__(self, filepath, model_prefix, vocab_size, character_coverage,\n",
    "                        model_type, input_sentence_size,\n",
    "                        shuffle_input_sentence, nm_rule,\n",
    "                        pad_id, unk_id, bos_id, eos_id, **kwargs):\n",
    "        \"\"\"\n",
    "        make sentence piece tokenizer\n",
    "        \"\"\"\n",
    "        spm.SentencePieceTrainer.train(\n",
    "            input=filepath,\n",
    "            model_prefix=model_prefix,\n",
    "            vocab_size=vocab_size,\n",
    "            character_coverage=character_coverage,\n",
    "            model_type=model_type,\n",
    "            input_sentence_size=input_sentence_size,\n",
    "            shuffle_input_sentence=shuffle_input_sentence,\n",
    "            normalization_rule_name=nm_rule,\n",
    "            pad_id=pad_id,\n",
    "            unk_id=unk_id,\n",
    "            bos_id=bos_id,\n",
    "            eos_id=eos_id,\n",
    "        )\n",
    "    \n",
    "    def tokenize(self):\n",
    "        \"\"\"\n",
    "        Do tokenization and return tokenized data and max length of tokens.\n",
    "\n",
    "        Return: (english tokens set, chinese tokens set, maximum length of tokens)\n",
    "        \"\"\"\n",
    "        self.__check_spm_model__()\n",
    "        # load data\n",
    "        en_corpus = []\n",
    "        zh_corpus = []\n",
    "        with open(self.datapath[0], 'r') as ifile:\n",
    "            for s in ifile:\n",
    "                en_corpus.append(s.strip())\n",
    "        with open(self.datapath[1], 'r') as ifile:\n",
    "            for s in ifile:\n",
    "                zh_corpus.append(s.strip())\n",
    "        # tokenize\n",
    "        en_tokenizer, zh_tokenizer = self.get_tokenizers()\n",
    "        pad_id = self.spm_config['pad_id']\n",
    "        bos_id = self.spm_config['bos_id']\n",
    "        eos_id = self.spm_config['eos_id']\n",
    "        en_tokens = []\n",
    "        zh_tokens = []\n",
    "        for i in range(len(en_corpus)):\n",
    "            en_tokens.append([bos_id] + en_tokenizer.encode(en_corpus[i], out_type=int) + [eos_id])\n",
    "            zh_tokens.append([bos_id] + zh_tokenizer.encode(zh_corpus[i], out_type=int) + [eos_id])\n",
    "        max_tokens_len = len(max([max(en_tokens, key=len), max(zh_tokens, key=len)], key=len))\n",
    "        return en_tokens, zh_tokens, max_tokens_len\n",
    "\n",
    "    def get_tokenizers(self):\n",
    "        \"\"\"\n",
    "        Return: (english tokenizer, chinese tokenizer)\n",
    "        \"\"\"\n",
    "        self.__check_spm_model__()\n",
    "        en_model_path, zh_model_path = self.__get_model_path__()    \n",
    "        return spm.SentencePieceProcessor(model_file=str(en_model_path)), \\\n",
    "               spm.SentencePieceProcessor(model_file=str(zh_model_path))\n",
    "        \n",
    "def save_tokens_set(save_dir, src_data, tgt_data, length):\n",
    "    \"\"\"save tokens set into :obj:`train.json` file\"\"\"\n",
    "    file_dir = Path(save_dir)\n",
    "    file_dir.mkdir(parents=True, exist_ok=True)\n",
    "    js_obj = {\n",
    "        \"length\" : length,\n",
    "        \"src_data\" : src_data,\n",
    "        \"tgt_data\" : tgt_data\n",
    "    }\n",
    "    with open(file_dir / \"train.json\", 'w') as ofile:\n",
    "        json.dump(js_obj, ofile)\n",
    "\n",
    "\n",
    "# test tokenizer\n",
    "spmTokenHandler = SpmTokenHandler(**config)\n",
    "en_tokens_set, zh_tokens_set, max_len = spmTokenHandler.tokenize()\n",
    "print(f\"max tokens length {max_len}\")\n",
    "en_tokenizer, zh_tokenizer = spmTokenHandler.get_tokenizers()\n",
    "s = 'hello world , this is for test .'\n",
    "print(en_tokenizer.EncodeAsPieces(s))\n",
    "print(en_tokenizer.EncodeAsIds(s))\n",
    "sz = '椰奶不是產自椰羊所以請不要騷擾椰羊！'\n",
    "print(zh_tokenizer.EncodeAsPieces(sz))\n",
    "print(zh_tokenizer.EncodeAsIds(sz))\n",
    "print(zh_tokenizer.DecodeIds([2044, 4825, 3531, 28, 2280, 2108, 4825, 3594, 15, 2578, 465, 4097, 3356, 4825, 3594, 2413]))\n",
    "\n",
    "\n",
    "# test save/load\n",
    "save_tokens_set(\"./token/data\", en_tokens_set, zh_tokens_set, max_len)\n",
    "js_obj = {}\n",
    "with open(\"./token/data/train.json\", 'r') as ifile:\n",
    "    js_obj = json.load(ifile)\n",
    "print(f\"tokens length : {js_obj['length']}\")\n",
    "for i in range(5):\n",
    "    print(en_tokenizer.decode(js_obj['src_data'][i]))\n",
    "    print(zh_tokenizer.decode(js_obj['tgt_data'][i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "def set_logger(log_name : str):\n",
    "    \"\"\"write log under given log_path\"\"\"\n",
    "    log_dir = Path(\"./log\")\n",
    "    log_dir.mkdir(parents=True, exist_ok=True)\n",
    "    log_path = log_dir / f\"{datetime.datetime.now().date()}.log\"\n",
    "\n",
    "    logger = logging.getLogger(log_name)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    formater_s = logging.Formatter(\"%(name)s [%(levelname)s] %(message)s\")\n",
    "    formater_f = logging.Formatter(\"%(asctime)s - %(name)s [%(levelname)s] %(message)s\")\n",
    "    \n",
    "    if not logger.handlers:\n",
    "        # logging to file\n",
    "        file_handler = logging.FileHandler(log_path)\n",
    "        file_handler.setFormatter(formater_f)\n",
    "        logger.addHandler(file_handler)\n",
    "        # logging to console\n",
    "        stream_handler = logging.StreamHandler()\n",
    "        stream_handler.setFormatter(formater_s)\n",
    "        logger.addHandler(stream_handler)\n",
    "    \n",
    "    return logger\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset & DataLoader\n",
    "\n",
    "Data (`./token/data/train.json`) structure:\n",
    "\n",
    "- `length` : (int) length of each data\n",
    "- `src_data` : (list of int-list) english data\n",
    "- `tgt_data` : (list of int-list) chinese data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from torch.utils.data import Dataset\n",
    "#from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "class myDataset(Dataset):\n",
    "    def __init__(self, filepath, pad_id):\n",
    "        js_obj = None\n",
    "        with open(filepath, 'r') as fp:\n",
    "            js_obj = json.load(fp)\n",
    "        self.feature_len = js_obj['length']\n",
    "        self.src_data = js_obj['src_data']\n",
    "        self.tgt_data = js_obj['tgt_data']\n",
    "        self.__padding__(pad_id)\n",
    "\n",
    "    def __padding__(self, pad_id):\n",
    "        \"\"\"padding data to specific length\"\"\"\n",
    "        # shorten the names\n",
    "        src = self.src_data\n",
    "        tgt = self.tgt_data\n",
    "        for i in range(len(src)):\n",
    "            src[i] = src[i] + [pad_id for j in range(self.feature_len - len(src[i]))]\n",
    "            tgt[i] = tgt[i] + [pad_id for j in range(self.feature_len - len(tgt[i]))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.LongTensor(self.src_data[idx]), torch.LongTensor(self.tgt_data[idx])\n",
    "    \n",
    "    def get_features_len(self):\n",
    "        return self.feature_len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "\n",
    "\n",
    "def get_dataloader(filepath, batch_size, n_workers, pad_id, collate_fn):\n",
    "    \"\"\"\n",
    "    Get dataloaders for training and validating.\n",
    "    \n",
    "    Return: train_loader, valid_loader, features_len\n",
    "    \"\"\"\n",
    "    dataset = myDataset(filepath, pad_id)\n",
    "    features_len = dataset.get_features_len()\n",
    "    # split dataset into training and validating\n",
    "    trainlen = int(0.9 * len(dataset))\n",
    "    lengths = [trainlen, len(dataset)-trainlen]\n",
    "    trainset, validset = random_split(dataset, lengths)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        trainset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=n_workers,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        validset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=n_workers,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    return train_loader, valid_loader, features_len\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Reference:\n",
    "- https://zhuanlan.zhihu.com/p/106902569\n",
    "- https://github.com/hemingkx/ChineseNMT/blob/master/model.py\n",
    "- https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html\n",
    "- https://pytorch.org/docs/stable/generated/torch.Tensor.expand.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodelTest = mk_model(PositionalEncoding, 8000, 32, 400, 128).to(\"mps\")\\nsrc = torch.randint(0,7999,(32,400,1),dtype = torch.long).to(\"mps\")\\ntgt = torch.randint(0,7999,(32,400,1),dtype = torch.long).to(\"mps\")\\nsrc_mask = torch.cat(((torch.FloatTensor(32,200).uniform_() > 1),(torch.FloatTensor(32,200).uniform_() > 0.15)),dim =1).to(\"mps\")\\ntgt_mask = torch.cat(((torch.FloatTensor(32,100).uniform_() > 1),(torch.FloatTensor(32,300).uniform_() > 0.15)),dim =1).to(\"mps\")\\n#summary(modelTest, src=src, tgt=tgt, src_key_padding_mask=src_mask, tgt_key_padding_mask=tgt_mask)\\n#summary(modelTest.preprocessor, src=src, tgt=tgt)\\n#print(modelTest.state_dict())\\nprob = modelTest(src, tgt, src_mask, tgt_mask)\\nprint(prob.shape)\\n\\nmemory = modelTest.encode(src, src_mask)\\nprint(memory.shape)\\noutput = modelTest.decode(tgt, memory, tgt_mask)\\nprint(output.shape)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torchinfo import summary\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=1000):\n",
    "        super().__init__()\n",
    "        # position encoding matrix : (length, dim)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        # position index\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        # division term\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.) / d_model))\n",
    "        # assign calculated number into the matrix\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        # add batch dimension to pe : (batch, length, dim)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x : (batch, length, dim)\n",
    "        x = x + self.pe[:, : x.size(1), :]\n",
    "        return x\n",
    "    \n",
    "class Preprocessor(nn.Module):\n",
    "    def __init__(self, pos_encode, vocab_sz, d_model):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedder = nn.Embedding(vocab_sz, d_model)\n",
    "        self.pos_encoder = pos_encode(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x : (batch, length, dim)\n",
    "        # embedding\n",
    "        x = self.embedder(x).squeeze()\n",
    "        # positional encoding\n",
    "        x = self.pos_encoder(x)\n",
    "        return x\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_model, nhead=2, encoder_layer=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)\n",
    "        encoder_norm = nn.LayerNorm(d_model)\n",
    "        self.encoder = nn.TransformerEncoder(self.encoder_layer, encoder_layer, encoder_norm)\n",
    "\n",
    "    def forward(self, src, src_key_padding_mask):\n",
    "        # src : (batch, length, dim)\n",
    "        # src : (length, batch, dim)\n",
    "        src = src.transpose(0, 1)\n",
    "        src = self.encoder(src, src_key_padding_mask=src_key_padding_mask)\n",
    "        return src\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, batch_size, length, d_model, nhead=2, decoder_layer=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.nhead = nhead\n",
    "        # attention-mask should be put into device after created\n",
    "        attn_mask = self.__get_attn_mask__(batch_size, length)\n",
    "        self.register_buffer('attn_mask', attn_mask)\n",
    "        # decoder\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead)\n",
    "        decoder_norm = nn.LayerNorm(d_model)\n",
    "        self.decoder = nn.TransformerDecoder(self.decoder_layer, decoder_layer, decoder_norm)\n",
    "        # generator(feedforward)\n",
    "        self.generator = nn.Linear(d_model, vocab_size)\n",
    "    \n",
    "    def __get_attn_mask__(self, batch_size, mask_size):\n",
    "        \"\"\"create attention mask and put it to device\"\"\"\n",
    "        mask = torch.ones((mask_size, mask_size))\n",
    "        mask = (mask.triu(diagonal=1) == 1)\n",
    "        return mask.expand(batch_size * self.nhead, -1, -1)\n",
    "    \n",
    "    def forward(self, tgt, memory, tgt_key_padding_mask):\n",
    "        # memory : (length, batch, dim)\n",
    "        # tgt : (batch, length, dim)\n",
    "        # tgt : (length, batch, dim)\n",
    "        tgt = tgt.transpose(0, 1)\n",
    "        # output : (length, batch, dim)\n",
    "        output = self.decoder(tgt, memory, tgt_mask=self.attn_mask, tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "        # output : (batch, length, dim)\n",
    "        output = output.transpose(0, 1)\n",
    "        # feedforward\n",
    "        output = self.generator(output)\n",
    "        output = F.log_softmax(output, -1)\n",
    "        return output\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, preprocessor_src : Preprocessor, preprocessor_tgt : Preprocessor,\n",
    "                 encoder : Encoder, decoder : Decoder):\n",
    "        super().__init__()\n",
    "\n",
    "        self.preprocessor_src = preprocessor_src\n",
    "        self.preprocessor_tgt = preprocessor_tgt\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def encode(self, src, src_key_padding_mask):\n",
    "        src = self.preprocessor_src(src)\n",
    "        src = self.encoder(src, src_key_padding_mask)\n",
    "        return src\n",
    "    \n",
    "    def decode(self, tgt, memory, tgt_key_padding_mask):\n",
    "        tgt = self.preprocessor_tgt(tgt)\n",
    "        tgt = self.decoder(tgt, memory, tgt_key_padding_mask)\n",
    "        return tgt\n",
    "\n",
    "    def forward(self, src, tgt, src_key_padding_mask,tgt_key_padding_mask):\n",
    "        # src : (batch, length, dim)\n",
    "        # tgt : (batch, length, dim)\n",
    "        # memory : (length, batch, dim)\n",
    "        memory = self.encode(src, src_key_padding_mask)\n",
    "        # output : (batch, length, dim)\n",
    "        output = self.decode(tgt, memory, tgt_key_padding_mask)\n",
    "        return output\n",
    "\n",
    "\n",
    "def mk_model(pos_encode, vocab_size, batch_size, length, d_model, nhead_encoder=2, nhead_decoder=2, encoder_layer=2, decoder_layer=2, **kwargs):\n",
    "    \"\"\"\n",
    "    making model\n",
    "    \"\"\"\n",
    "    preprocessor_src = Preprocessor(pos_encode, vocab_size, d_model)\n",
    "    preprocessor_tgt = Preprocessor(pos_encode, vocab_size, d_model)\n",
    "    encoder = Encoder(d_model, nhead_encoder, encoder_layer)\n",
    "    decoder = Decoder(vocab_size, batch_size, length, d_model, nhead_decoder, decoder_layer)\n",
    "    transformer = Transformer(preprocessor_src, preprocessor_tgt, encoder, decoder)\n",
    "    return transformer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "modelTest = mk_model(PositionalEncoding, 8000, 32, 400, 128).to(\"mps\")\n",
    "src = torch.randint(0,7999,(32,400,1),dtype = torch.long).to(\"mps\")\n",
    "tgt = torch.randint(0,7999,(32,400,1),dtype = torch.long).to(\"mps\")\n",
    "src_mask = torch.cat(((torch.FloatTensor(32,200).uniform_() > 1),(torch.FloatTensor(32,200).uniform_() > 0.15)),dim =1).to(\"mps\")\n",
    "tgt_mask = torch.cat(((torch.FloatTensor(32,100).uniform_() > 1),(torch.FloatTensor(32,300).uniform_() > 0.15)),dim =1).to(\"mps\")\n",
    "#summary(modelTest, src=src, tgt=tgt, src_key_padding_mask=src_mask, tgt_key_padding_mask=tgt_mask)\n",
    "#summary(modelTest.preprocessor, src=src, tgt=tgt)\n",
    "#print(modelTest.state_dict())\n",
    "prob = modelTest(src, tgt, src_mask, tgt_mask)\n",
    "print(prob.shape)\n",
    "\n",
    "memory = modelTest.encode(src, src_mask)\n",
    "print(memory.shape)\n",
    "output = modelTest.decode(tgt, memory, tgt_mask)\n",
    "print(output.shape)\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criterion & Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criterion : Label-Smoothing Cross Entropy Loss\n",
    "\n",
    "Reference:\n",
    "- https://zhuanlan.zhihu.com/p/518262647\n",
    "- https://github.com/hemingkx/ChineseNMT/blob/master/model.py\n",
    "- https://blog.csdn.net/lihuanyu520/article/details/132164972\n",
    "- HW05\n",
    "\n",
    "Also refers `7. Model Regularization via Label Smoothing`: https://arxiv.org/pdf/1512.00567.pdf\n",
    "- $p$ : output prediction\n",
    "- $q$ : target label (one-hot vector)\n",
    "- $q'$ : label-smoothing\n",
    "\n",
    "$$ H(q', p) = -\\sum_{k=1}^K\\log p(k)q'(k) = (1-\\epsilon)H(q, p) + \\epsilon H(u, p) $$\n",
    "\n",
    "where\n",
    "- $K$ is total labels\n",
    "- $\\epsilon=\\frac{smoothing\\ rate}{K}$\n",
    "- $u(k)=\\frac{1}{K}$\n",
    "- $q'(k) = (1 - \\epsilon)\\delta_{k, y} + \\frac{\\epsilon}{K}$, $y$ is true label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class LabelSmoothingCrossEntropyLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Brief \n",
    "    y^ = < y_1^, y_2^, y_3^, ... , y_n^ > is an n-dimensional one-hot vector, for which\n",
    "\n",
    "        y_i^ =\n",
    "\n",
    "         1  if i = target\n",
    "\n",
    "         0  if i != target\n",
    "\n",
    "    Instead of using above one-hot vector to compute cross entropy, we use smoothed\n",
    "    y~ = < y_1~, y_2~, ... , y_n~ >, which\n",
    "\n",
    "        y_i~ =\n",
    "\n",
    "          1 - e     if i = target\n",
    "\n",
    "          e / (n-1) if i != target\n",
    "\n",
    "    where e is a small number between 0 and 1. (usually named e as 'smoothing').\n",
    "    \n",
    "    Note y_i~ may differ, for example, in `7. Model Regularization via Label Smoothing`,\n",
    "        y_i~ =\n",
    "\n",
    "         1 - e + e/n    if i = target\n",
    "\n",
    "         e/n            if i != target\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, padding_idx=None, smoothing=0.0, **kwargs):\n",
    "        \"\"\"\n",
    "        padding_idx :\n",
    "            the index in spm-dictionary that used for padding. \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.padding_idx = padding_idx\n",
    "        self.smoothing = smoothing\n",
    "        self.labels_num = vocab_size\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        \"\"\"\n",
    "        Calculate the loss based on https://arxiv.org/pdf/1512.00567.pdf\n",
    "\n",
    "        Note that the loss should exclude those words after the padding index\n",
    "        found in target. for example: padding_idx = 0\n",
    "\n",
    "        x = torch.tensor([[[0.001, 0.002, 0.003, 0.004],\n",
    "                           [0.010, 0.020, 0.030, 0.040],\n",
    "                           [0.100, 0.200, 0.300, 0.400],\n",
    "                           [1.000, 2.000, 3.000, 4.000]],\n",
    "\n",
    "                          [[10.00, 20.00, 30.00, 40.00],\n",
    "                           [100.0, 200.0, 300.0, 400.0],\n",
    "                           [1000., 2000., 3000., 4000.],\n",
    "                           [10000, 20000, 30000, 40000]]])\n",
    "\n",
    "        target = torch.tensor([[2,\n",
    "                                1,\n",
    "                                0,\n",
    "                                0],\n",
    "                                \n",
    "                                [2,\n",
    "                                3,\n",
    "                                1,\n",
    "                                0]])\n",
    "        \n",
    "        values in x should be count into loss are:\n",
    "\n",
    "        x = torch.tensor([[[0.001, 0.002, 0.003, 0.004],\n",
    "                           [0.010, 0.020, 0.030, 0.040],\n",
    "                           [-----, -----, -----, -----],\n",
    "                           [-----, -----, -----, -----]],\n",
    "\n",
    "                          [[10.00, 20.00, 30.00, 40.00],\n",
    "                           [100.0, 200.0, 300.0, 400.0],\n",
    "                           [1000., 2000., 3000., 4000.],\n",
    "                           [-----, -----, -----, -----]]])\n",
    "\n",
    "        Args:\n",
    "        - x  :\n",
    "            (batch, length, dim = vocab_sz), predictions made by model\n",
    "        - target :\n",
    "            (batch, length, dim = 1 = label index in spm-dictionary)\n",
    "        \"\"\"\n",
    "        if target.dim() == x.dim() - 1:\n",
    "            target = target.unsqueeze(-1)\n",
    "\n",
    "        # gather values in x for Hqp\n",
    "        Hqp = -x.gather(dim=-1, index=target)\n",
    "        # sum up dimensional values of x to Hup\n",
    "        Hup = -x.sum(dim=-1, keepdim=True)\n",
    "\n",
    "        # exclude those padded values, i.e, set them as 0\n",
    "        if self.padding_idx is not None:\n",
    "            pad_mask = target.eq(self.padding_idx)\n",
    "            Hqp.masked_fill_(pad_mask, 0.0)\n",
    "            Hup.masked_fill_(pad_mask, 0.0)\n",
    "\n",
    "        Hqp = Hqp.sum()\n",
    "        Hup = Hup.sum() / self.labels_num\n",
    "        mean_loss = ( (1 - self.smoothing) * Hqp + self.smoothing * Hup ).mean()\n",
    "        return mean_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer : NoamOpt\n",
    "\n",
    "Reference:\n",
    "- https://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
    "- https://github.com/hemingkx/ChineseNMT/blob/master/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NoamOpt:\n",
    "    def __init__(self, vocab_size, factor, warmup, optimizer, **kwargs):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = vocab_size\n",
    "        self._rate = 0\n",
    "\n",
    "    def __rate__(self, step = None):\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return self.factor * (self.model_size ** (-0.5) * min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
    "\n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        self._rate = self.__rate__()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = self._rate\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "    \n",
    "# plot NoamOpt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "opts = [NoamOpt(512, 1, 4000, None), \n",
    "        NoamOpt(512, 1, 8000, None),\n",
    "        NoamOpt(256, 1, 4000, None)]\n",
    "plt.plot(np.arange(1, 20000), [[opt.__rate__(i) for opt in opts] for i in range(1, 20000)])\n",
    "plt.legend([\"512:4000\", \"512:8000\", \"256:4000\"])\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    \"\"\"collect data in batch, used in collate_fn\"\"\"\n",
    "    def __init__(self, src, tgt, src_key_padding_mask, tgt_key_padding_mask):\n",
    "        self.src = src\n",
    "        self.tgt = tgt\n",
    "        self.src_key_padding_mask = src_key_padding_mask\n",
    "        self.tgt_key_padding_mask = tgt_key_padding_mask\n",
    "    \n",
    "    def to(self, device):\n",
    "        return Batch(self.src.to(device), self.tgt.to(device), self.src_key_padding_mask.to(device), self.tgt_key_padding_mask.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s2s-transformer [INFO] mps is used.\n",
      "s2s-transformer [INFO] Training/Validating data loaded.\n",
      "s2s-transformer [INFO] Model created.\n",
      "s2s-transformer [INFO] Criterion set.\n",
      "s2s-transformer [INFO] ===Start training===\n",
      "  0%|          | 0/347 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 5.09 GB, other allocations: 3.48 GB, max allowed: 9.07 GB). Tried to allocate 1.64 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 125\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;28mprint\u001b[39m(epoch_loss)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 125\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 106\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(batch_size, n_workers, n_epochs, datapath_config, spm_config, criterion_config, noamOpt_config, model_config)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader):\n\u001b[1;32m    105\u001b[0m     batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 106\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtgt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(preds, batch\u001b[38;5;241m.\u001b[39mtgt)\n\u001b[1;32m    108\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/complexa_ML21_3a/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[6], line 117\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, src, tgt, src_key_padding_mask, tgt_key_padding_mask)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, src, tgt, src_key_padding_mask,tgt_key_padding_mask):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# src : (batch, length, dim)\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# tgt : (batch, length, dim)\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# memory : (length, batch, dim)\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# output : (batch, length, dim)\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(tgt, memory, tgt_key_padding_mask)\n",
      "Cell \u001b[0;32mIn[6], line 105\u001b[0m, in \u001b[0;36mTransformer.encode\u001b[0;34m(self, src, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, src, src_key_padding_mask):\n\u001b[1;32m    104\u001b[0m     src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessor_src(src)\n\u001b[0;32m--> 105\u001b[0m     src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m src\n",
      "File \u001b[0;32m~/anaconda3/envs/complexa_ML21_3a/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[6], line 55\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, src, src_key_padding_mask)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, src, src_key_padding_mask):\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# src : (batch, length, dim)\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m# src : (length, batch, dim)\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     src \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 55\u001b[0m     src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m src\n",
      "File \u001b[0;32m~/anaconda3/envs/complexa_ML21_3a/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/complexa_ML21_3a/lib/python3.10/site-packages/torch/nn/modules/transformer.py:315\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m make_causal\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 315\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    318\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/complexa_ML21_3a/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/complexa_ML21_3a/lib/python3.10/site-packages/torch/nn/modules/transformer.py:591\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    589\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 591\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    592\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/complexa_ML21_3a/lib/python3.10/site-packages/torch/nn/modules/transformer.py:599\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor,\n\u001b[1;32m    598\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 599\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/complexa_ML21_3a/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/complexa_ML21_3a/lib/python3.10/site-packages/torch/nn/modules/activation.py:1205\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1191\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1192\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1202\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1203\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1205\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/anaconda3/envs/complexa_ML21_3a/lib/python3.10/site-packages/torch/nn/functional.py:5373\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5370\u001b[0m k \u001b[38;5;241m=\u001b[39m k\u001b[38;5;241m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[1;32m   5371\u001b[0m v \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[0;32m-> 5373\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5374\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(bsz \u001b[38;5;241m*\u001b[39m tgt_len, embed_dim)\n\u001b[1;32m   5376\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 5.09 GB, other allocations: 3.48 GB, max allowed: 9.07 GB). Tried to allocate 1.64 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"arguements\"\"\"\n",
    "    config = {\n",
    "        \"batch_size\" : 1024,\n",
    "        \"n_workers\" : 0,\n",
    "        \"n_epochs\" : 1,\n",
    "        \"datapath_config\" : {\n",
    "            \"clean\" : [\"./data/clean/clean.en\", \"./data/clean/clean.zh\"],\n",
    "            \"token\" : \"./token/data/train.json\",\n",
    "        },\n",
    "        \"spm_config\" : {\n",
    "            \"vocab_size\" : 8000,\n",
    "            \"dir\" : \"./token\",\n",
    "            \"model_type\" : \"bpe\",\n",
    "            \"nm_rule\" : \"nmt_nfkc_cf\",\n",
    "            \"character_coverage\" : 1,\n",
    "            \"input_sentence_size\" : 1e6,\n",
    "            \"shuffle_input_sentence\" : True,\n",
    "            \"pad_id\" : 0,\n",
    "            \"unk_id\" : 1,\n",
    "            \"bos_id\" : 2,\n",
    "            \"eos_id\" : 3,\n",
    "        },\n",
    "        \"criterion_config\" : {\n",
    "            \"smoothing\" : 0.1,\n",
    "        },\n",
    "        \"noamOpt_config\" : {\n",
    "            \"factor\" : 1,\n",
    "            \"warmup\" : 1000,\n",
    "        },\n",
    "        \"model_config\" : {\n",
    "            \"pos_encode\" : PositionalEncoding,\n",
    "            \"d_model\" : 128,\n",
    "            \"nhead_encoder\" : 2,\n",
    "            \"nhead_decoder\" : 2,\n",
    "            \"encoder_layer\" : 2,\n",
    "            \"decoder_layer\" : 2,\n",
    "        },\n",
    "    }\n",
    "    return config\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    device = (\n",
    "        \"gpu\" if torch.cuda.is_available()\n",
    "        else \"mps\" if torch.backends.mps.is_available()\n",
    "        else \"cpu\"\n",
    "    )\n",
    "    return device\n",
    "\n",
    "def main(\n",
    "        batch_size,\n",
    "        n_workers,\n",
    "        n_epochs,\n",
    "        datapath_config,\n",
    "        spm_config,        \n",
    "        criterion_config,\n",
    "        noamOpt_config,\n",
    "        model_config,\n",
    "):\n",
    "    logger = set_logger(\"s2s-transformer\")\n",
    "\n",
    "    device = get_device()\n",
    "    logger.info(f\"{device} is used.\")\n",
    "\n",
    "    vocab_size = spm_config['vocab_size']\n",
    "\n",
    "    def collate_fn(batch):\n",
    "        # src, tgt is tuple when using zip(*)\n",
    "        src, tgt = zip(*batch)\n",
    "        # turn src, tgt back to tensor\n",
    "        src = torch.tensor(np.asarray(src))\n",
    "        tgt = torch.tensor(np.asarray(tgt))        \n",
    "        src_key_padding_mask = (src == spm_config['pad_id'])\n",
    "        tgt_key_padding_mask = (tgt == spm_config['pad_id'])\n",
    "        return Batch(src, tgt, src_key_padding_mask, tgt_key_padding_mask)\n",
    "    \n",
    "    train_loader, valid_loader, features_len = get_dataloader(datapath_config['token'], batch_size, n_workers, spm_config['pad_id'], collate_fn)\n",
    "    logger.info(\"Training/Validating data loaded.\")\n",
    "    \n",
    "    model = mk_model(vocab_size=vocab_size, batch_size=batch_size, length=features_len, **model_config).to(device)\n",
    "    logger.info(\"Model created.\")\n",
    "\n",
    "    criterion = LabelSmoothingCrossEntropyLoss(vocab_size=vocab_size, padding_idx=spm_config['pad_id'], **criterion_config)\n",
    "    optimizer = AdamW(params=model.parameters(), lr=0.0, betas=(0.9, 0.98), eps=1e-9)\n",
    "    noamOpt = NoamOpt(vocab_size=vocab_size, optimizer=optimizer, **noamOpt_config)\n",
    "    logger.info(\"Criterion set.\")\n",
    "\n",
    "    # --TODO--\n",
    "    # training\n",
    "    logger.info(\"===Start training===\")\n",
    "    for i in range(n_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        model.train()\n",
    "        for batch in tqdm(train_loader):\n",
    "            batch = batch.to(device)\n",
    "            preds = model(batch.src, batch.tgt, batch.src_key_padding_mask, batch.tgt_key_padding_mask)\n",
    "            loss = criterion(preds, batch.tgt)\n",
    "            loss.backward()\n",
    "            noamOpt.step()\n",
    "            noamOpt.zero_grad()\n",
    "            epoch_loss += loss.item()\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        for batch in tqdm(valid_loader):\n",
    "            batch.to(device)\n",
    "            with torch.no_grad():\n",
    "                # ---TODO---:\n",
    "                # validating\n",
    "                ...\n",
    "        \"\"\"\n",
    "        print(epoch_loss)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(**parse_args())\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "complexa_ML21_3a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
